import sys
import os
import pandas as pd
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_precision
from langchain_groq import ChatGroq
from langchain_core.embeddings import Embeddings
from dotenv import load_dotenv

# --- SETUP ÄÆ¯á»œNG DáºªN ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config.vector_store import get_vector_store
from config.embed import load_embed
from api.langchain_utils import get_conversational_rag_chain

load_dotenv()
api_key = os.getenv("MY_API_KEY")

# ==============================================================================
# ğŸ‘‡ CLASS WRAPPER ÄÃƒ FIX Lá»–I VALIDATION
# ==============================================================================
class LlamaIndexToLangchainWrapper(Embeddings):
    def __init__(self, llama_model):
        # LÆ°u model tháº­t vÃ o biáº¿n khÃ¡c Ä‘á»ƒ dÃ¹ng tÃ­nh toÃ¡n
        self.internal_model = llama_model
        # ğŸ‘‡ QUAN TRá»ŒNG: GÃ¡n tÃªn model dáº¡ng String Ä‘á»ƒ Ragas khÃ´ng bÃ¡o lá»—i Pydantic
        self.model = "AITeamVN/Vietnamese_Embedding"

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        # Gá»i model tháº­t Ä‘á»ƒ embed
        return [self.internal_model.get_text_embedding(t) for t in texts]

    def embed_query(self, text: str) -> list[float]:
        # Gá»i model tháº­t Ä‘á»ƒ embed
        return self.internal_model.get_query_embedding(text)
# ==============================================================================

def run_evaluation():
    print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng Lucfin RAG Ä‘á»ƒ cháº¥m thi...")
    
    # 1. Load Model & Wrap láº¡i
    print("   - Loading Embedding Model...")
    llama_embed_model = load_embed()
    ragas_embed_model = LlamaIndexToLangchainWrapper(llama_embed_model) 

    print("   - Loading Vector Store...")
    vector_store = get_vector_store()
    
    # Load LLM
    print("   - Loading LLMs...")
    # DÃ¹ng Llama 3.3 70B thay cho Qwen Ä‘Ã£ bá»‹ xÃ³a
    llm_rag = ChatGroq(model="llama-3.3-70b-versatile", api_key=api_key, temperature=0)
    rag_chain = get_conversational_rag_chain(llm_rag, vector_store)
    
    judge_llm = ChatGroq(model="llama-3.3-70b-versatile", api_key=api_key, temperature=0)

    # 2. Äá»c Testset & Cáº¯t ngáº¯n
    testset_path = os.path.join("evaluation", "testset_ground_truth.csv")
    if not os.path.exists(testset_path):
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file testset_ground_truth.csv")
        return

    full_df = pd.read_csv(testset_path)
    
    # ğŸ‘‡ Cáº®T Láº¤Y 5 CÃ‚U (Äáº£m báº£o cáº¯t ngay tá»« Ä‘áº§u)
    df = full_df.head(10).copy()
    print(f"ğŸ“¥ ÄÃ£ táº£i {len(df)} cÃ¢u há»i (Test nhanh 5 cÃ¢u).")

    # 3. Bot lÃ m bÃ i (Inference)
    answers = []
    contexts = []
    
    print("ğŸ¤– Bot Ä‘ang tráº£ lá»i...")
    for index, row in df.iterrows():
        question = row['question']
        try:
            # Fake chat history rá»—ng
            response = rag_chain.invoke({"input": question, "chat_history": []})
            
            ans_text = str(response['answer'])
            # Láº¥y list ná»™i dung context
            source_docs = [doc.page_content for doc in response['context']]
            
            answers.append(ans_text)
            contexts.append(source_docs)
            print(f"   âœ… Done Q{index+1}")
        except Exception as e:
            print(f"   âŒ Lá»—i Q{index+1}: {e}")
            answers.append("Lá»—i há»‡ thá»‘ng")
            contexts.append(["No context found"])

    # 4. Chuáº©n bá»‹ dá»¯ liá»‡u cháº¥m
    ragas_data = {
        'question': df['question'].tolist(),
        'answer': answers,
        'contexts': contexts,
        'ground_truth': df['ground_truth'].tolist()
    }
    dataset = Dataset.from_dict(ragas_data)

    # 5. Cháº¥m Ä‘iá»ƒm
    print("\nâš–ï¸  GiÃ¡m kháº£o Ragas Ä‘ang cháº¥m Ä‘iá»ƒm...")
    # LÆ°u Ã½: Cáº£nh bÃ¡o "1 generations instead of 3" lÃ  bÃ¬nh thÆ°á»ng vá»›i Groq, cá»© ká»‡ nÃ³.
    results = evaluate(
        dataset=dataset,
        metrics=[faithfulness, answer_relevancy, context_precision],
        llm=judge_llm, 
        embeddings=ragas_embed_model # DÃ¹ng Wrapper Ä‘Ã£ fix
    )

    # 6. Xuáº¥t káº¿t quáº£
    print("\nğŸ“Š Káº¾T QUáº¢ FINAL:")
    print(results)
    
    output_excel = os.path.join("evaluation", "lucfin_final_report.xlsx")
    results.to_pandas().to_excel(output_excel, index=False)
    print(f"âœ… Xong! File Excel lÆ°u táº¡i: {output_excel}")

if __name__ == "__main__":
    run_evaluation()