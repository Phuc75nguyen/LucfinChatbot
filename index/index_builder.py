import pandas as pd
from llama_index.core import VectorStoreIndex, Settings
from llama_index.core.schema import TextNode # DÃ¹ng TextNode thay vÃ¬ Document Ä‘á»ƒ kiá»ƒm soÃ¡t tá»‘t hÆ¡n
from config.embed import load_embed

def build_index(data_path="data/foods.csv", persist_dir="FoodDB"):
    # 1. Load Model GPU
    print("ğŸ”Œ Äang khá»Ÿi Ä‘á»™ng Model trÃªn GPU...")
    embed_model = load_embed()
    Settings.embed_model = embed_model # CÃ i Ä‘áº·t Global
    
    # 2. Äá»c Data
    print("ğŸ“‚ Äang Ä‘á»c CSV...")
    df = pd.read_csv(data_path)
    
    # 3. Táº¡o Nodes (Thay vÃ¬ Document)
    # Node lÃ  Ä‘Æ¡n vá»‹ nhá» nháº¥t Ä‘á»ƒ lÆ°u vÃ o Vector DB
    nodes = []
    print("âš™ï¸ Äang xá»­ lÃ½ dá»¯ liá»‡u thÃ´ thÃ nh Nodes...")
    
    for _, row in df.iterrows():
        # Táº¡o ná»™i dung text Ä‘á»ƒ search
        text_content = (
            f"MÃ³n Äƒn: {row['dish_name']}\n"
            f"PhÃ¢n loáº¡i: {row['dish_type']}\n"
            f"MÃ´ táº£: {row['description']}\n"
            f"ThÃ nh pháº§n: {row['ingredients']}\n"
            f"CÃ¡ch náº¥u: {row['cooking_method']}"
        )
        
        # Metadata
        metadata = {
            "dish_name": str(row['dish_name']),
            "calories": int(row['calories']) if pd.notna(row['calories']) else 0,
            "protein": int(row['protein']) if pd.notna(row['protein']) else 0,
            "fat": int(row['fat']) if pd.notna(row['fat']) else 0,
            "image_link": str(row['image_link']) if pd.notna(row['image_link']) else ""
        }
        
        # Táº¡o Node
        node = TextNode(text=text_content, metadata=metadata)
        nodes.append(node)
    
    # 4. MANUAL EMBEDDING (ÄÃ¢y lÃ  bÆ°á»›c tÄƒng tá»‘c)
    # Thay vÃ¬ Ä‘á»ƒ Index tá»± cháº¡y, ta tÃ¡ch text ra vÃ  Ã©p Model cháº¡y 1 láº§n
    print(f"ğŸš€ Báº¯t Ä‘áº§u nhÃºng Vector cho {len(nodes)} mÃ³n Äƒn (Tá»‘c Ä‘á»™ cao)...")
    
    # Láº¥y danh sÃ¡ch text tá»« cÃ¡c nodes
    text_chunks = [node.get_content(metadata_mode="embed") for node in nodes]
    
    # Gá»i hÃ m get_text_embedding_batch trá»±c tiáº¿p (HÃ m nÃ y chÃ­nh lÃ  cÃ¡i cháº¡y nhanh trong debug_gpu.py)
    # show_progress=True Ä‘á»ƒ hiá»ƒn thá»‹ thanh loading chuáº©n
    embeddings = embed_model.get_text_embedding_batch(text_chunks, show_progress=True)
    
    # GÃ¡n ngÆ°á»£c vector vÃ o node
    for node, embedding in zip(nodes, embeddings):
        node.embedding = embedding

    print("âš¡ Äang Ä‘Ã³ng gÃ³i vÃ o Index...")
    
    # 5. Táº¡o Index tá»« cÃ¡c Nodes Ä‘Ã£ cÃ³ sáºµn Vector (KhÃ´ng cáº§n tÃ­nh toÃ¡n láº¡i)
    index = VectorStoreIndex(nodes)
    
    # 6. LÆ°u láº¡i
    index.storage_context.persist(persist_dir=persist_dir)
    print(f"âœ… ÄÃ£ lÆ°u xong {len(nodes)} mÃ³n Äƒn vÃ o '{persist_dir}' thÃ nh cÃ´ng!")
    return index

if __name__ == "__main__":
    build_index()